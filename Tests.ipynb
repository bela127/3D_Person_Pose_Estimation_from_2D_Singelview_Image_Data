{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing ./src\n",
      "Building wheels for collected packages: ShAReD-Net\n",
      "  Building wheel for ShAReD-Net (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ShAReD-Net: filename=ShAReD_Net-1.0-py3-none-any.whl size=35237 sha256=5c6ed68b0b30f1ad0bebe5d97f2c793020a360a4ffd17b3d2472a046a999c854\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xy9hb5ij/wheels/22/c3/70/c7c197844357b787f75a5309992d7aa6bb1d79ad298e7a9445\n",
      "Successfully built ShAReD-Net\n",
      "Installing collected packages: ShAReD-Net\n",
      "  Attempting uninstall: ShAReD-Net\n",
      "    Found existing installation: ShAReD-Net 1.0\n",
      "    Uninstalling ShAReD-Net-1.0:\n",
      "      Successfully uninstalled ShAReD-Net-1.0\n",
      "Successfully installed ShAReD-Net-1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install ./src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200308\n",
      "4 Physical GPUs, 3 Logical GPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 2), dtype=float32, numpy=array([[[[0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[1:], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "\n",
    "conv = tf.keras.layers.Conv2D(2,3)\n",
    "conv(tf.zeros([1,3,3,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.activation.base as activation_base\n",
    "activation_base.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.layer.aggregation as aggregation\n",
    "aggregation.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.layer.base as layer_base\n",
    "layer_base.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.layer.heatmap_1d as heatmap_1d\n",
    "heatmap_1d.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.layer.heatmap_2d as heatmap_2d\n",
    "heatmap_2d.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.modules.feature as feature\n",
    "feature.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.modules.base as base\n",
    "base.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.modules.extractor as extract\n",
    "extract.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.modules.detector as detector\n",
    "detector.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.model.modules.estimator as estimator\n",
    "estimator.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dev20200308\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "TrainingModel (TensorShape([1, 384, 384, 3]), (TensorShape([2]), TensorShape([2, 15, 3])), TensorShape([]), TensorShape([]))\n",
      "tracing TrainingModel (None, None, None, 3) (TensorShape([None]), TensorShape([None, 15, 3])) () ()\n",
      "MultiScaleFeatureExtractor [TensorShape([None, None, None, 3]), TensorShape([]), TensorShape([])]\n",
      "ScaledFeatures [TensorShape([None, None, None, 3]), TensorShape([]), TensorShape([])]\n",
      "Extractor (None, None, None, 3)\n",
      "FrustumScaler [TensorShape([None, None, None, 32]), TensorShape([]), TensorShape([])]\n",
      "MultiscaleShAReD [(TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32])), (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32])), (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32]))]\n",
      "MultiscaleShAReDStage [(TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32])), (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32])), (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32]))]\n",
      "ShAReDHourGlass (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32]))\n",
      "ShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32]))\n",
      "ResAttention (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32]))\n",
      "Attention (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 32]))\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "ShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "ResAttention (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "Attention (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "ScaledShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "Scale (None, None, None, 32)\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Scale (None, None, None, 136)\n",
      "Scale (None, None, None, 136)\n",
      "ShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Mix [TensorShape([None, None, None, 136]), TensorShape([None, None, None, 136]), TensorShape([None, None, None, 136])]\n",
      "Merge [TensorShape([None, None, None, 136]), TensorShape([None, None, None, 136])]\n",
      "Merge (TensorShape([None, None, None, 136]), TensorShape([None, None, None, 136]), TensorShape([None, None, None, 136]))\n",
      "Merge [TensorShape([None, None, None, 136]), TensorShape([None, None, None, 136])]\n",
      "SelfShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272]))\n",
      "ShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention [TensorShape([None, None, None, 272]), TensorShape([None, None, None, 136])]\n",
      "ShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 544])]\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 544])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 544])]\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "SelfShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 408]))\n",
      "ShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 408])]\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 408])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 408])]\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Attention [TensorShape([None, None, None, 408]), TensorShape([None, None, None, 136])]\n",
      "ShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 816])]\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 816])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 816])]\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "SelfShAReD (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272]))\n",
      "ShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 272])]\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Attention [TensorShape([None, None, None, 272]), TensorShape([None, None, None, 136])]\n",
      "ShAReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 544])]\n",
      "ResAttention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 544])]\n",
      "Attention [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 544])]\n",
      "ShReD [TensorShape([None, None, None, 32]), TensorShape([None, None, None, 96])]\n",
      "DenseModule (None, None, None, 128)\n",
      "DenseBlock (None, None, None, 128)\n",
      "BnDoConfReluConfRelu (None, None, None, 128)\n",
      "Interleave (TensorShape([None, None, None, 32]), TensorShape([None, None, None, 136]))\n",
      "Combine3D [TensorShape([None, None, None, 64]), TensorShape([None, None, None, 64]), TensorShape([None, None, None, 64])]\n",
      "PersonDetector (None, 3, None, None, 64)\n",
      "Expand3D (None, 3, None, None, 64)\n",
      "person_pos_from_pose (None, 15, 3)\n",
      "tracing person_pos_from_pose (None, 15, 3)\n",
      "person_loss [TensorShape([None, None, None, 6]), (TensorShape([None]), TensorShape([None, 3]))]\n",
      "person_pos_to_heat_map (TensorShape([None]), TensorShape([None, 3]))\n",
      "person_pos_to_indexes [TensorShape([None]), TensorShape([None, 3])]\n",
      "tracing person_pos_to_indexes (None,) (None, 3)\n",
      "and params (3,) (3,) (3,)\n",
      "heat_map_to_weights (None, None, None, None)\n",
      "Expand3D (None, 3, None, None, 64)\n",
      "CropROI3D [TensorShape([None, 6, None, None, 32]), TensorShape([None, 4])]\n",
      "PoseEstimator (None, 11, 11, 32)\n",
      "SelfShAReD [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 32])]\n",
      "ShAReD [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 32])]\n",
      "ResAttention [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 32])]\n",
      "Attention [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 32])]\n",
      "ShReD [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 96])]\n",
      "DenseModule (None, 11, 11, 128)\n",
      "DenseBlock (None, 11, 11, 128)\n",
      "BnDoConfReluConfRelu (None, 11, 11, 128)\n",
      "DenseBlock (None, 11, 11, 136)\n",
      "BnDoConfReluConfRelu (None, 11, 11, 136)\n",
      "DenseBlock (None, 11, 11, 144)\n",
      "BnDoConfReluConfRelu (None, 11, 11, 144)\n",
      "Attention [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 152])]\n",
      "ShAReD [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 64])]\n",
      "ResAttention [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 64])]\n",
      "Attention [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 64])]\n",
      "ShReD [TensorShape([None, 11, 11, 32]), TensorShape([None, 11, 11, 96])]\n",
      "DenseModule (None, 11, 11, 128)\n",
      "DenseBlock (None, 11, 11, 128)\n",
      "BnDoConfReluConfRelu (None, 11, 11, 128)\n",
      "DenseBlock (None, 11, 11, 136)\n",
      "BnDoConfReluConfRelu (None, 11, 11, 136)\n",
      "DenseBlock (None, 11, 11, 144)\n",
      "BnDoConfReluConfRelu (None, 11, 11, 144)\n",
      "Scale (None, 11, 11, 152)\n",
      "Scale (None, 11, 11, 32)\n",
      "ShAReD [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 75])]\n",
      "ResAttention [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 75])]\n",
      "Attention [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 75])]\n",
      "ShReD [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 111])]\n",
      "DenseModule (None, 13, 13, 148)\n",
      "DenseBlock (None, 13, 13, 148)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 148)\n",
      "DenseBlock (None, 13, 13, 156)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 156)\n",
      "DenseBlock (None, 13, 13, 164)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 164)\n",
      "SelfShAReD (TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 172]))\n",
      "ShAReD [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 172])]\n",
      "ResAttention [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 172])]\n",
      "Attention [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 172])]\n",
      "ShReD [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 111])]\n",
      "DenseModule (None, 13, 13, 148)\n",
      "DenseBlock (None, 13, 13, 148)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 148)\n",
      "DenseBlock (None, 13, 13, 156)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 156)\n",
      "DenseBlock (None, 13, 13, 164)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 164)\n",
      "Attention [TensorShape([None, 13, 13, 172]), TensorShape([None, 13, 13, 172])]\n",
      "ShAReD [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 344])]\n",
      "ResAttention [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 344])]\n",
      "Attention [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 344])]\n",
      "ShReD [TensorShape([None, 13, 13, 37]), TensorShape([None, 13, 13, 111])]\n",
      "DenseModule (None, 13, 13, 148)\n",
      "DenseBlock (None, 13, 13, 148)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 148)\n",
      "DenseBlock (None, 13, 13, 156)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 156)\n",
      "DenseBlock (None, 13, 13, 164)\n",
      "BnDoConfReluConfRelu (None, 13, 13, 164)\n",
      "Scale (None, 13, 13, 172)\n",
      "Scale (None, 13, 13, 37)\n",
      "ShAReD [TensorShape([None, 20, 20, 25]), TensorShape([None, 20, 20, 50])]\n",
      "ResAttention [TensorShape([None, 20, 20, 25]), TensorShape([None, 20, 20, 50])]\n",
      "Attention [TensorShape([None, 20, 20, 25]), TensorShape([None, 20, 20, 50])]\n",
      "ShReD [TensorShape([None, 20, 20, 25]), TensorShape([None, 20, 20, 75])]\n",
      "DenseModule (None, 20, 20, 100)\n",
      "DenseBlock (None, 20, 20, 100)\n",
      "BnDoConfReluConfRelu (None, 20, 20, 100)\n",
      "DenseBlock (None, 20, 20, 108)\n",
      "BnDoConfReluConfRelu (None, 20, 20, 108)\n",
      "DenseBlock (None, 20, 20, 116)\n",
      "BnDoConfReluConfRelu (None, 20, 20, 116)\n",
      "ShAReD (TensorShape([None, 20, 20, 25]), TensorShape([None, 20, 20, 124]))\n",
      "ResAttention (TensorShape([None, 20, 20, 25]), TensorShape([None, 20, 20, 124]))\n",
      "Attention (TensorShape([None, 20, 20, 25]), TensorShape([None, 20, 20, 124]))\n",
      "ShReD [TensorShape([None, 20, 20, 25]), TensorShape([None, 20, 20, 75])]\n",
      "DenseModule (None, 20, 20, 100)\n",
      "DenseBlock (None, 20, 20, 100)\n",
      "BnDoConfReluConfRelu (None, 20, 20, 100)\n",
      "DenseBlock (None, 20, 20, 108)\n",
      "BnDoConfReluConfRelu (None, 20, 20, 108)\n",
      "DenseBlock (None, 20, 20, 116)\n",
      "BnDoConfReluConfRelu (None, 20, 20, 116)\n",
      "pose_loss [TensorShape([None, 20, 20, 25]), TensorShape([None, 15, 3])]\n",
      "keypoint_batch_to_pose_gt (None, 15, 3)\n",
      "pose_loss2d [TensorShape([None, 20, 20, 15]), TensorShape([None, 15, 2])]\n",
      "pose_loss_depth [TensorShape([None, 20, 20, 10]), TensorShape([None]), TensorShape([None, 3])]\n",
      "limb_length (None, 15, 3)\n",
      "symmetry_loss (None, None, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracing TrainingModel (None, None, None, 3) (TensorShape([None]), TensorShape([None, 15, 3])) () ()\n",
      "tracing person_pos_from_pose (None, 15, 3)\n",
      "tracing person_pos_to_indexes (None,) (None, 3)\n",
      "and params (3,) (3,) (3,)\n",
      "tracing TrainingModel (None, None, None, 3) (TensorShape([None]), TensorShape([None, 15, 3])) () ()\n",
      "tracing person_pos_from_pose (None, 15, 3)\n",
      "tracing person_pos_to_indexes (None,) (None, 3)\n",
      "and params (3,) (3,) (3,)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2').\n"
     ]
    }
   ],
   "source": [
    "import ShAReD_Net.training.run_train_train_model as run_train_model\n",
    "run_train_model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.training.loss.base as loss_base\n",
    "loss_base.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ShAReD_Net.training.model as train_model\n",
    "train_model.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ShAReD_Net.training.train as train\n",
    "train.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ShAReD_Net.training.run_train as run_train\n",
    "run_train.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def run(tensor):\n",
    "    tf.TensorArray(dtype=tf.float32, size=tf.cast(tensor, dtype = tf.float32), dynamic_size=False)\n",
    "\n",
    "v = tf.Variable(5,dtype=tf.float32)\n",
    "run(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
