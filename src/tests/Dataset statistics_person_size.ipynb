{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/media/inferics/DataSets/Public_Datasets/JTA-Dataset/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /media/inferics/DataSets/Public_Datasets/JTA-Dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ShAReD_Net.configure import config\n",
    "\n",
    "config.dataset.IMG_PATH = \"/dataset/jta/images\"\n",
    "config.dataset.ANNO_PATH = \"/dataset/jta/new_image_annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/dataset/jta/images/train/seq_188/338.jpg'\n",
      "b'/dataset/jta/images/train/seq_57/201.jpg'\n",
      "b'/dataset/jta/images/train/seq_199/42.png'\n",
      "b'/dataset/jta/images/train/seq_104/694.jpg'\n",
      "b'/dataset/jta/images/train/seq_46/321.jpg'\n"
     ]
    }
   ],
   "source": [
    "image_path = pathlib.Path(config.dataset.IMG_PATH)\n",
    "ANNO_PATH = tf.constant(config.dataset.ANNO_PATH)\n",
    "\n",
    "image_ds = tf.data.Dataset.list_files(str(image_path/'train/*/*')).shuffle(10000)\n",
    "\n",
    "for f in image_ds.take(5):\n",
    "    print(f.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def to_cam_space(joint):\n",
    "    cam_transform = config.dataset.cam_transform\n",
    "    joint_homog = tf.linalg.matvec(cam_transform, joint)\n",
    "    cam_space_joint = joint_homog / joint_homog[2]\n",
    "    return cam_space_joint\n",
    "\n",
    "def show_batch(image_batch, label_batch):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(len(image_batch)):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        poses = label_batch[n]\n",
    "        for pose in poses:\n",
    "            for joint in pose:\n",
    "                text = f\"[{joint[0]},{joint[1]}]\"\n",
    "                print(text)\n",
    "                cam_space_joint = to_cam_space(joint)\n",
    "                plt.text(cam_space_joint[0],cam_space_joint[1], text)\n",
    "        plt.axis('off')\n",
    "\n",
    "def get_annotation_path(img_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(img_path, os.path.sep)\n",
    "    data_split = parts[-3]\n",
    "    seq = parts[-2]\n",
    "    img_name = parts[-1]\n",
    "\n",
    "    anno_name = tf.strings.split(img_name, '.')[0] + '.npy'\n",
    "    anno_path = tf.strings.join([ANNO_PATH,data_split,seq,anno_name], separator='/')\n",
    "    # The second to last is the class-directory\n",
    "    return anno_path\n",
    "\n",
    "def get_annotation(anno_path):\n",
    "    poses = np.load(anno_path, allow_pickle=True)\n",
    "    annos = np.empty([len(poses),15,3], dtype=np.float32)\n",
    "    for i, pose in enumerate(poses):\n",
    "        annos[i,0,0] = pose[1].x3d\n",
    "        annos[i,0,1] = pose[1].y3d\n",
    "        annos[i,0,2] = pose[1].z3d\n",
    "\n",
    "        annos[i,1,0] = pose[2].x3d\n",
    "        annos[i,1,1] = pose[2].y3d\n",
    "        annos[i,1,2] = pose[2].z3d\n",
    "\n",
    "        annos[i,2,0] = pose[15].x3d\n",
    "        annos[i,2,1] = pose[15].y3d\n",
    "        annos[i,2,2] = pose[15].z3d\n",
    "\n",
    "        annos[i,3,0] = pose[4].x3d\n",
    "        annos[i,3,1] = pose[4].y3d\n",
    "        annos[i,3,2] = pose[4].z3d\n",
    "\n",
    "        annos[i,4,0] = pose[8].x3d\n",
    "        annos[i,4,1] = pose[8].y3d\n",
    "        annos[i,4,2] = pose[8].z3d\n",
    "\n",
    "        annos[i,5,0] = pose[5].x3d\n",
    "        annos[i,5,1] = pose[5].y3d\n",
    "        annos[i,5,2] = pose[5].z3d\n",
    "\n",
    "        annos[i,6,0] = pose[9].x3d\n",
    "        annos[i,6,1] = pose[9].y3d\n",
    "        annos[i,6,2] = pose[9].z3d\n",
    "\n",
    "        annos[i,7,0] = pose[6].x3d\n",
    "        annos[i,7,1] = pose[6].y3d\n",
    "        annos[i,7,2] = pose[6].z3d\n",
    "\n",
    "        annos[i,8,0] = pose[10].x3d\n",
    "        annos[i,8,1] = pose[10].y3d\n",
    "        annos[i,8,2] = pose[10].z3d\n",
    "\n",
    "        annos[i,9,0] = pose[16].x3d\n",
    "        annos[i,9,1] = pose[16].y3d\n",
    "        annos[i,9,2] = pose[16].z3d\n",
    "\n",
    "        annos[i,10,0] = pose[19].x3d\n",
    "        annos[i,10,1] = pose[19].y3d\n",
    "        annos[i,10,2] = pose[19].z3d\n",
    "\n",
    "        annos[i,11,0] = pose[17].x3d\n",
    "        annos[i,11,1] = pose[17].y3d\n",
    "        annos[i,11,2] = pose[17].z3d\n",
    "\n",
    "        annos[i,12,0] = pose[20].x3d\n",
    "        annos[i,12,1] = pose[20].y3d\n",
    "        annos[i,12,2] = pose[20].z3d\n",
    "\n",
    "        annos[i,13,0] = pose[18].x3d\n",
    "        annos[i,13,1] = pose[18].y3d\n",
    "        annos[i,13,2] = pose[18].z3d\n",
    "\n",
    "        annos[i,14,0] = pose[21].x3d\n",
    "        annos[i,14,1] = pose[21].y3d\n",
    "        annos[i,14,2] = pose[21].z3d\n",
    "\n",
    "    return annos\n",
    "\n",
    "def process_path(file_path):\n",
    "    anno_path = get_annotation_path(file_path)\n",
    "    anno = tf.numpy_function(get_annotation, [anno_path], tf.float32)\n",
    "    anno.set_shape([None,15,3])\n",
    "\n",
    "    return file_path, anno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ShAReD_Net.data.load.dataset_jta.joint as joint\n",
    "import ShAReD_Net.data.load.dataset_jta.pose as pose\n",
    "sys.modules['joint'] = joint\n",
    "sys.modules['pose'] = pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = image_ds.map(process_path,\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_pos_from_pose(path, poses):\n",
    "    poss = tf.reduce_mean(poses, axis=-2)\n",
    "    return path, poss, poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pose_ds = labeled_ds.map(person_pos_from_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def poss_and_poses_to_img(path, poss, poses):\n",
    "    poss_img = poss_to_img(poss)\n",
    "    poses_img = poses_to_img(poses)\n",
    "\n",
    "    return path, poss_img, poses_img\n",
    "\n",
    "def poss_to_img(poss):\n",
    "    cam_transform = config.dataset.cam_transform\n",
    "    poss_homog = tf.linalg.matvec(cam_transform, poss)\n",
    "    poss_img = poss_homog / poss_homog[:,None,-1]\n",
    "    return tf.concat([poss_img[:,:-1],poss[:,None,-1]], axis=-1)\n",
    "\n",
    "def poses_to_img(poses):\n",
    "    cam_transform = config.dataset.cam_transform\n",
    "    poses_homog = tf.linalg.matvec(cam_transform, poses)\n",
    "    poses_img = poses_homog / poses_homog[:,:,None,-1]\n",
    "    return tf.concat([poses_img[:,:,:-1],poses[:,:,None,-1]], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_ds = pos_pose_ds.map(poss_and_poses_to_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def poss_and_poses_to_cut(cut_dist, dist_delta, upscaling, cam_intr_f):\n",
    "    def to_cut(img, poss, poses):\n",
    "        poss_cut = poss_to_cut(poss, cut_dist, upscaling, cam_intr_f)\n",
    "        poses_cut = poses_to_cut(poses, cut_dist, upscaling, cam_intr_f)\n",
    "        poss_cut_filtered, poses_cut_filtered = filter_poss_and_pose(poss_cut, poses_cut, cut_dist, dist_delta)\n",
    "        return img, poss_cut_filtered, poses_cut_filtered\n",
    "    return to_cut\n",
    "\n",
    "def poss_to_cut(poss, dist, upscaling, cam_intr_f):\n",
    "    poss_cut = poss * upscaling * dist / cam_intr_f\n",
    "    return tf.concat([poss_cut[:,:-1],poss[:,None,-1]], axis=-1)\n",
    "\n",
    "def poses_to_cut(poses, dist, upscaling, cam_intr_f):\n",
    "    poses_cut = poses * upscaling * dist / cam_intr_f\n",
    "    return tf.concat([poses_cut[:,:,:-1],poses[:,:,None,-1]], axis=-1)\n",
    "\n",
    "def filter_poss_and_pose(poss, poses, dist, dist_delta):\n",
    "    indexes = tf.where(tf.abs(poss[:,-1]-dist) < dist_delta)\n",
    "    filtered_poss = tf.gather_nd(poss, indexes)\n",
    "    filtered_poses = tf.gather_nd(poses, indexes)\n",
    "\n",
    "    return filtered_poss, filtered_poses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_ds = cam_ds.map(poss_and_poses_to_cut(cut_dist=15, dist_delta=config.model.data.cut_delta, upscaling=config.model.data.upscaling, cam_intr_f = config.dataset.cam_intr_f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO TEST VALIDATION to singel item datasets\n",
    "def to_rel_poses(path, poss, poses):\n",
    "    return poses-poss[:,None,:]\n",
    "\n",
    "poses_ds = cut_ds.map(to_rel_poses)\n",
    "poses_ds = poses_ds.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_keypoints(pose):\n",
    "    return tf.concat(tf.unstack(pose),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_ds = poses_ds.map(to_keypoints).take(3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = tfds.as_numpy(keypoint_ds)\n",
    "keypoint_df = pd.DataFrame(data=numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.514739990234375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([15.,  0.,  3.,  0.,  5.,  2.,  3.,  1.,  2.,  1.,  2.,  2.,  2.,\n",
       "         3.,  0.,  0.,  2.,  0.,  0.,  2.]),\n",
       " array([ 0.40666485,  3.31206861,  6.21747236,  9.12287612, 12.02827988,\n",
       "        14.93368363, 17.83908739, 20.74449115, 23.64989491, 26.55529866,\n",
       "        29.46070242, 32.36610618, 35.27150993, 38.17691369, 41.08231745,\n",
       "        43.9877212 , 46.89312496, 49.79852872, 52.70393248, 55.60933623,\n",
       "        58.51473999]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inter_person_size_df = (keypoint_df.max() - keypoint_df.min())\n",
    "print(inter_person_size_df.max())\n",
    "plt.hist(inter_person_size_df, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_size_df = keypoint_df.T.max() - keypoint_df.T.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.65481567382812\n",
      "39.18544006347656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,   9.,   7.,   7.,  11.,  50., 149., 302., 351., 335.,\n",
       "        335., 318., 289., 239., 248., 197., 101.,  37.,  14.]),\n",
       " array([39.18544006, 40.90890884, 42.63237762, 44.35584641, 46.07931519,\n",
       "        47.80278397, 49.52625275, 51.24972153, 52.97319031, 54.69665909,\n",
       "        56.42012787, 58.14359665, 59.86706543, 61.59053421, 63.31400299,\n",
       "        65.03747177, 66.76094055, 68.48440933, 70.20787811, 71.93134689,\n",
       "        73.65481567]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(person_size_df.max())\n",
    "print(person_size_df.min())\n",
    "\n",
    "plt.hist(person_size_df, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upscaling = 32 -> mean_person_size = 42, max_person_size = 60, min_person_size = 37 -> 11/15/10 ROI\n",
    "### upscaling = 36 -> mean_person_size = 47, max_person_size = 67, min_person_size = 42 -> 12/17/11 ROI\n",
    "### upscaling = 50 -> mean_person_size = 67, max_person_size = 95, min_person_size = 60 -> 17/24/15 ROI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
